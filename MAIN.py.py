# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zu8-H_qxiL3bR-SKqM7VjjielNFMzZUD
"""

import csv
from bs4 import BeautifulSoup

def parse_html(red_main):
  with open(red_main, 'r') as file:
    soup = BeautifulSoup(file, 'html.parser')

  data = []
  for a_tag in soup.find_all('a', class_="truncate font-bold text-neutral-content-strong text-12 hover:underline"):
    item = {}
    item['name'] = a_tag.text.strip() if a_tag.text else ""

    comments_div = a_tag.find_next('div', id="-post-rtjson-content", class_="py-0 xs:mx-xs mx-2xs inline-block max-w-full")
    item['comments'] = comments_div.text.strip() if comments_div else ""

    votes_span = a_tag.find_next('span', class_="faceplate-number pretty")
    item['votes'] = votes_span.text.strip() if votes_span else ""

    data.append(item)

  return data

def write_to_csv(data, output_file):
  """Writes the parsed data to a CSV file.

  Args:
    data: A list of dictionaries, where each dictionary represents a parsed item.
    output_file: Path to the output CSV file.
  """

  with open(output_file, 'w', newline='') as csvfile:
    fieldnames = ['name', 'comments', 'votes']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(data)

if __name__ == '__main__':
  html_file = 'red_main.html'  # Replace with your file path
  csv_file = 'output.csv'

  data = parse_html(html_file)
  write_to_csv(data, csv_file)